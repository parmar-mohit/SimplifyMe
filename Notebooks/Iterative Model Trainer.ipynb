{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1nOaXjnedD-FCjjmfjlvVqlZOUlxDr0NZ","authorship_tag":"ABX9TyOao4cMLjG1N8UE1FXarEt4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Iterative Model Trainer\n","\n"],"metadata":{"id":"sdrm05sAGATH"}},{"cell_type":"markdown","source":["## Training Progress"],"metadata":{"id":"-6nEGoRvGZhJ"}},{"cell_type":"markdown","source":["100 Iterations Completed"],"metadata":{"id":"w-VTG2ZMCmCy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ye4sLfWtF84q"},"outputs":[],"source":["!pip install transformers datasets sacrebleu rouge_score torch accelerate torchvision -q -U"]},{"cell_type":"code","source":["from transformers import pipeline\n","from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoTokenizer, BartForConditionalGeneration, DataCollatorForSeq2Seq\n","from transformers import TrainingArguments, Trainer\n","from google.colab import drive\n","import torch\n","import random\n","import pandas as pd"],"metadata":{"id":"TkRILwduGse7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"id":"_9SkNcZAGuW3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for first time\n","# model_path = \"facebook/bart-large-cnn\"\n","\n","# for nth iteration\n","model_path = \"./drive/MyDrive/Submission/BE Project Group No 31/Model/iter_trained_model\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n","model = BartForConditionalGeneration.from_pretrained(model_path).to(device)"],"metadata":{"id":"A8MRGF7sHExP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 101\n","\n","train_df = pd.DataFrame()\n","val_df = pd.DataFrame()\n","\n","for current_data_iteration in range(i,i+2):\n","  train_dataset_path = f\"./drive/MyDrive/Submission/BE Project Group No 31/Data/training_data{current_data_iteration}.csv\"\n","  val_dataset_path = f\"./drive/MyDrive/Submission/BE Project Group No 31/Data/val_data{current_data_iteration}.csv\"\n","  train_df = pd.concat([train_df, pd.read_csv(train_dataset_path)])\n","  val_df = pd.concat([val_df, pd.read_csv(val_dataset_path)])\n","\n","\n","train_dataset = Dataset.from_pandas( train_df )\n","val_dataset = Dataset.from_pandas( val_df )\n","papers_dataset = DatasetDict({\"train\":train_dataset, \"validation\":val_dataset})"],"metadata":{"id":"NAsIXj5lHWqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_function(examples):\n","    input_encodings = tokenizer(examples[\"article\"], max_length=1024, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","\n","    with tokenizer.as_target_tokenizer():\n","      target_encodings = tokenizer(examples[\"abstract\"],max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","\n","    return {\n","        \"input_ids\" : input_encodings[\"input_ids\"],\n","        \"attention_mask\" : input_encodings[\"attention_mask\"],\n","        \"labels\" : target_encodings[\"input_ids\"]\n","    }\n","\n","papers_dataset_processed = papers_dataset.map(tokenize_function,batched=True)"],"metadata":{"id":"sn7FmzcoHvID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["papers_dataset_processed"],"metadata":{"id":"-LYeFKEJH15O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer,model=model)"],"metadata":{"id":"kKxHVVcKH2V3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"./bart-papers-trained-output\",\n","    per_device_train_batch_size=1,\n","    save_total_limit=2,\n","    num_train_epochs=2,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=250,\n","    save_steps=1000,\n","    logging_dir=\"./logs\",\n","    logging_steps=100,\n","    remove_unused_columns=True,  # Set to True to remove extra columns in the dataset\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=papers_dataset_processed[\"train\"],\n","    eval_dataset=papers_dataset_processed[\"validation\"],\n",")"],"metadata":{"id":"_qisQ8VxKXZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"gEH3TDOQKakx","colab":{"base_uri":"https://localhost:8080/","height":133},"outputId":"5953255b-5b7b-429a-a961-740a91939a0e"},"execution_count":null,"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='56' max='5100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  56/5100 26:24 < 41:07:14, 0.03 it/s, Epoch 0.02/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='67' max='5100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  67/5100 31:46 < 41:00:52, 0.03 it/s, Epoch 0.03/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["trainer.save_model(\"./drive/MyDrive/Submission/BE Project Group No 31/Model/iter_trained_model\")"],"metadata":{"id":"_95DxE-pKd7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"{current_data_iteration}th Iteration Training Completed\")"],"metadata":{"id":"2x8ABmpFKgh_"},"execution_count":null,"outputs":[]}]}